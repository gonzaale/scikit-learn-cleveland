{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First we will import necessary libraries."
      ],
      "metadata": {},
      "id": "0ff80620"
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv, DataFrame\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {},
      "id": "ee3b225a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will read the data and eliminate rows with invalid values."
      ],
      "metadata": {},
      "id": "59c4f444"
    },
    {
      "cell_type": "code",
      "source": [
        "data = DataFrame(read_csv(\"processed.cleveland.data\", header = None, na_values =\"?\")).dropna()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {},
      "id": "02c46902"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the variable we're interested in predicting is not binary. It is 0 when the patient does not have heart disease, and ranges from 1 to 4 depending on the severity of the disease. Since we're only interested in predicting whether the patient has the disease or not, we will convert all values from 2 to 4 into 1."
      ],
      "metadata": {},
      "id": "3bedaf42"
    },
    {
      "cell_type": "code",
      "source": [
        "data[13].mask(data[13] > 0, 1, inplace = True)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {},
      "id": "bf83b160"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can start building the models, we will split the data set into a training set, containing 70% of observations, and a testing set, containing 30% of observations. The training set will be used to train the models, and the testing set will be used to test their accuracy."
      ],
      "metadata": {},
      "id": "7455ccb0"
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 0:13]\n",
        "y = data.iloc[:, 13]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {},
      "id": "5d132d11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support vector machines\n",
        "\n",
        "We are ready to start building the support vector machines.\n",
        "\n",
        "### Linear\n",
        "\n",
        "We start with a linear kernel.\n",
        "\n",
        "A linear kernel SVM has one important hyper-parameter: *C*, or cost. We can use a grid search to test different values of *C* and select the one that produces best results."
      ],
      "metadata": {},
      "id": "588a2d29"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_linear = GridSearchCV(svm.SVC(kernel = \"linear\"), [{\"C\": [0.01, 0.1, 0.5, 1, 10, 100]}]).fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {},
      "id": "061da98c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SVM can now be used to predict whether a patient has heart disease based on the given variables."
      ],
      "metadata": {},
      "id": "861f2995"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_linear.predict(X_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       1, 0], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {},
      "id": "822c6a91"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also determine its accuracy on the training set."
      ],
      "metadata": {},
      "id": "10bc0682"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_linear.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "0.8333333333333334"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {},
      "id": "33b283b3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we obtain an accuracy of 83.33%\n",
        "\n",
        "### Radial\n",
        "\n",
        "Now we will build a support vector machine with a radial kernel.\n",
        "\n",
        "We will tune the hyper-parameters like we did with the linear kernel, but we will also use a *gamma* value since we're using a radial kernel."
      ],
      "metadata": {},
      "id": "e25d9cb8"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf = GridSearchCV(svm.SVC(kernel = \"rbf\"), [{\"C\": [0.01, 0.1, 0.5, 1, 10, 100], \"gamma\": [0.01, 0.1, 1, 5]}]).fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {},
      "id": "f0fad9ae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we did before, we can use the model to make predictions using the testing set."
      ],
      "metadata": {},
      "id": "9bcaac6e"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf.predict(X_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "array([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 0], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {},
      "id": "e00e9621"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we test its accuracy."
      ],
      "metadata": {},
      "id": "c8ba9360"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "0.6"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {},
      "id": "13d88d90"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain an accuracy value of 60%.\n",
        "\n",
        "### Sigmoid\n",
        "\n",
        "Finally, we will build a sigmoid kernel SVM. Just like with the radial kernel, we will tune *C* and *gamma*."
      ],
      "metadata": {},
      "id": "57dff992"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_sigmoid = GridSearchCV(svm.SVC(kernel = \"sigmoid\"), [{\"C\": [0.01, 0.1, 0.5, 1, 10, 100], \"gamma\": [0.01, 0.1, 1, 5]}]).fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {},
      "id": "c026647e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the SVM to make predictions."
      ],
      "metadata": {},
      "id": "7f7b8f46"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_sigmoid.predict(X_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {},
      "id": "e0715b53"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we check its accuracy."
      ],
      "metadata": {},
      "id": "1f45d5e9"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_sigmoid.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "0.5666666666666667"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {},
      "id": "36a97765"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy for the sigmoid kernel SVM is 56.67%.\n",
        "\n",
        "## Multilayer perceptrons\n",
        "\n",
        "Now we will build multilayer perceptrons using various parameters.\n",
        "\n",
        "### Rectified linear unit function\n",
        "\n",
        "The rectified linear unit is an activation function that returns f(x) = max(0, x).\n",
        "\n",
        "#### SGD optimizer\n",
        "\n",
        "We will build two MLPs using the stochastic gradient descent optimizer and two different learning rates.\n",
        "\n",
        "##### SGD - learning rate 0.01"
      ],
      "metadata": {},
      "id": "d640d864"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_relu_sgd2 = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.01).fit(X_train, y_train)\n",
        "mlp_relu_sgd2.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "0.5666666666666667"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {},
      "id": "94cf6d4f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With these paremeters, the MLP has an accuracy of 56.67% on the testing data.\n",
        "\n",
        "##### SGD - learning rate 0.001"
      ],
      "metadata": {},
      "id": "f5489c0f"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_relu_sgd3 = MLPClassifier(activation = 'relu', solver = 'sgd', learning_rate_init = 0.001).fit(X_train, y_train)\n",
        "mlp_relu_sgd3.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "0.6555555555555556"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {},
      "id": "95f10983"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For these parameters the accuracy is 65.56%.\n",
        "\n",
        "#### Adam optimizer\n",
        "\n",
        "Similarly, we will build two MLPs using Adam, an extension of SGD.\n",
        "\n",
        "##### Adam - learning rate 0.01"
      ],
      "metadata": {},
      "id": "e55b8c94"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_relu_adam2 = MLPClassifier(activation = 'relu', solver = 'adam', learning_rate_init = 0.01).fit(X_train, y_train)\n",
        "mlp_relu_adam2.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "0.6111111111111112"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {},
      "id": "77c48c22"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see Adam performs much better, with a 61.11% accuracy on the testing data.\n",
        "\n",
        "##### Adam - learning rate 0.001"
      ],
      "metadata": {},
      "id": "467a3358"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_relu_adam3 = MLPClassifier(activation = 'relu', solver = 'adam', learning_rate_init = 0.001).fit(X_train, y_train)\n",
        "mlp_relu_adam3.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "0.8333333333333334"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {},
      "id": "ba090ad7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate 0.001 produces an accuracy of 83.33%, the highest so far.\n",
        "\n",
        "### Hyperbolic tangent function\n",
        "\n",
        "We will repeat this process using the hyperbolic tangent f(x) = tanh(x) activation function.\n",
        "\n",
        "#### SGD optimizer\n",
        "\n",
        "We use the same learning rates as before.\n",
        "\n",
        "##### SGD - learning rate 0.01"
      ],
      "metadata": {},
      "id": "ad49cde6"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_tanh_sgd2 = MLPClassifier(activation = 'tanh', solver = 'sgd', learning_rate_init = 0.01).fit(X_train, y_train)\n",
        "mlp_tanh_sgd2.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "0.43333333333333335"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {},
      "id": "a4139c6a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy is not very good, at 43.33%.\n",
        "\n",
        "##### SGD - learning rate 0.001"
      ],
      "metadata": {},
      "id": "f109e83d"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_tanh_sgd3 = MLPClassifier(activation = 'tanh', solver = 'sgd', learning_rate_init = 0.001).fit(X_train, y_train)\n",
        "mlp_tanh_sgd3.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "0.5666666666666667"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {},
      "id": "e6bf4cdc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time the accuracy is 56.67%.\n",
        "\n",
        "#### Adam optimizer\n",
        "\n",
        "Now we use the Adam optimizer.\n",
        "\n",
        "##### Adam - learning rate 0.01"
      ],
      "metadata": {},
      "id": "82d0fd6c"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_tanh_adam2 = MLPClassifier(activation = 'tanh', solver = 'adam', learning_rate_init = 0.01).fit(X_train, y_train)\n",
        "mlp_tanh_adam2.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "0.6444444444444445"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {},
      "id": "4206cded"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is better (64.44%) than when using the rectified linear unit function, but the difference is likely not large enough to consider statistically significant given the testing set's size.\n",
        "\n",
        "##### Adam - learning rate 0.001"
      ],
      "metadata": {},
      "id": "3d81d18f"
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_tanh_adam3 = MLPClassifier(activation = 'tanh', solver = 'adam', learning_rate_init = 0.001).fit(X_train, y_train)\n",
        "mlp_tanh_adam3.score(X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "0.6666666666666666"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {},
      "id": "ff8d7435"
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a 66.68% accuracy, the smaller learning rate didn't perform much better."
      ],
      "metadata": {},
      "id": "65ae56bb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}